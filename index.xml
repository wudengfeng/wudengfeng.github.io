<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>爬山人的博客</title>
    <link>https://wudengfeng.github.io/</link>
    <description>Recent content on 爬山人的博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 25 Jul 2020 01:38:39 +0800</lastBuildDate>
    
	<atom:link href="https://wudengfeng.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>过滤服务的实现</title>
      <link>https://wudengfeng.github.io/blog/filter_server/</link>
      <pubDate>Sat, 25 Jul 2020 01:38:39 +0800</pubDate>
      
      <guid>https://wudengfeng.github.io/blog/filter_server/</guid>
      <description> 背景 这是在我做一个个性化推荐系统中遇到的实际问题，我们都知道，一个个性化推荐系统大致包含特征获取，召回，过滤，排序这几个大的模块。考虑在过滤阶段，为了不给用户推送重复内容，我们需要记录每一个用户看过的内容。我选用的是redis来存储这些内容，最初的做法我尝试过使用set，list，string来存储，这几个方案在业务与性能上都存在一定问题。接下来我们具体看看上面的方案。
    实现方案 优点 存在的问题     Redis set 每一个用户一个key，set中的每个元素是用户已读的内容id。设置过期时间，定期失效。 1. 易于排查问题，只需要知道用户id，即可追查出用户已读内容。
2. set可以保证存储内容无重复，不需要考虑客户端重复上报已读的问题。 1. 当用户已读内容逐渐增多，很容易出现大key问题，这种用户变多，就会redis的性能带来很大的影响。
2. 用户已读的内容不能单独设置过期时间，我们假设是以一周为过期时间，上周已读的内容会同时失效，极端情况会出现这周第一天用户就刷到上周最后一天的内容，体验不好。   Redis list 每一个用户一个key，list中的每个元素是用户已读的内容id，并且每次有新内容进入时都放到list末尾。判断list长度，超过一定长度则从list首端剔除元素。 1. 相比set同时失效所有内容id，list可以保证了用户看到的最近n条内容不重复。 1. 每次都需要判断list长度，并且写入list的时候需要判断内容id是否已经存在，超过设置长度需要剔除元素，操作上复杂。
2. 依然存在用户内容变多，出现大key问题。   Redis string 每个用户id-内容id一个key。针对每个key设置失效时间 1. 方便控制每个用户对每个key过期时间。保证了用户在一定周期内，不会再看到已读的内容。
2. 不会有大key问题。 1. 仅仅根据用户id是不能确定用户已读内容的，需要知道内容id取判断，排查问题上带来一定的不方便
2. 随着用户已读内容变多，key会变的很多，需要大容量内存的redis来保证该方案。    我们可以看到不管使用哪个方案，都存在一个问题，那就是需要存储内容很多。尤其是redis将数据放在内存中，这样一来，如何又节约内存，又能很快的判断出用户是否对某个内容是否已读就成了需要解决的问题。在实际处理中，我最终采用了布隆过滤器来解决这个问题。接下来是具体的实现方案
实现方案 </description>
    </item>
    
    <item>
      <title>布隆过滤器</title>
      <link>https://wudengfeng.github.io/blog/bloom_filter/</link>
      <pubDate>Tue, 24 Mar 2020 22:50:32 +0800</pubDate>
      
      <guid>https://wudengfeng.github.io/blog/bloom_filter/</guid>
      <description>简介 布隆过滤器（Bloom Filter）是一种概率型数据结构。在允许一定误判的情况下，用于判断一个元素是否“可能在”，“一定不在”一个集合中。它由一个二进制向量和一系列哈希函数组成。
原理 首先我们准备一个bit array，将每一位都置为0。当我们需要添加一个元素到集合中时，使用n个hash函数取该元素的n个hash值，将每个hash值对bit array长度取模得到n个小于bit array长度的值，然后把bit array对应的这n个位置置为1，这样就完成了一次插入元素。当我们要判断某个元素是否在集合中，依然使用这n个hash函数，算出该元素在bit array中对应的n个位置，然后我们只要判断这n个位置是否都为1，如果都是1则说明该元素“可能”在集合中，否则“一定不在”集合中。
 为什么对应位都是1，是“可能”在集合中，这是因为不同元素算出来的hash值取模后的位数有可能是同一个位，导致出现该元素明明不在集合中，却被误判为在集合中。
 为什么对应位只要有一位不为1，就“一定不在”集合中，这是因为假设该元素在集合中，对应位一定会被置为1。
 这里我们就可以看出，布隆过滤器是会存在一定的误判的，但是只会有“假阳性”的情况。那么现在想想，一个布隆过滤器这样的误判率会是多少，由什么来决定误判率的大小呢？考虑这样的场景，当我们准备好一个bit array，长度为m，再准备n个函数函数组成一个布隆过滤器，当越来越多的元素进入，被置为1的位置越来越多，误判率也会升高，这时如果我们增加n的值，即使用更多的hash函数，每个元素的重叠位就会降低，可以缓解误判率的升高。又或者我们增加bit array的长度，允许更多的bit被置为1，也一样可以达到目的。所以误判率和bit array的长度还有hash函数的个数有关。具体的关系我们到下面再详细推导。
 rebuild过程。在业务使用中，我们往往都会固定好要使用的bit array长度和hash函数个数，当达到一定的误判率时，需要重新构建布隆过滤器。我们的选择是选用更长的bit array。将原来的bit array中置为1的位置映射到新的bit array中。
 这里有几个问题，为什么在误判率升高的情况下，不选用增加hash函数？因为再增加hash函数，需要重新计算每个元素的hash值，而我们又不知道原始元素的数据。 如何判定已经达到预期中的误判率？我们已经知道，误判率和bit array的长度m和hash函数个数n有关，我们可以在bit array前k个bit记录元素个数，当元素个数超过预期值，认为误判率到了预期的阈值。   rebuild的具体做法：//todo
特点 看了上面的介绍的原理，我们可以总结下布隆过滤器的特点
 使用bit array，大量节省空间 不存储原始数据 不可以删除，删除的话将n位的bit置为0，可能会影响到别的元素，因为别的元素计算的bit位也有可能是要被删除元素对应的位 存在一定的误判率，我们需要在业务场景和性能中找到平衡点，选取可以接受的误判率对应的bit array长度和hash函数个数 需要对逐渐增长的内容量做rebuild操作  代码实现 package main import ( &amp;quot;context&amp;quot; &amp;quot;fmt&amp;quot; &amp;quot;hash&amp;quot; &amp;quot;hash/fnv&amp;quot; &amp;quot;math/big&amp;quot; &amp;quot;github.com/spaolacci/murmur3&amp;quot; ) const ( Seed = 12138 BitNum = 8 BitExist uint = 1 BitNotExist uint = 0 ) type BloomFilter struct { Bits *big.</description>
    </item>
    
  </channel>
</rss>